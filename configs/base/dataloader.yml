train_dataloader:
  dataset:
    transforms:
      ops:
        - {type: RandomPhotometricDistort, p: 0.5}
        - {type: RandomZoomOut, fill: 0}
        - {type: RandomIoUCrop, p: 0.8}
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: RandomHorizontalFlip}
        - {type: Resize, size: [640, 640]}   # ðŸ‘ˆ keep fixed size for fairness
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: True}
      policy:
        name: stop_epoch
        epoch: 25    # ðŸ‘ˆ sync with flat_epoch (50 total â†’ 25 is halfway)
        ops: ['Mosaic', 'RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']

  collate_fn:
    type: BatchImageCollateFunction
    base_size: 640
    base_size_repeat: 1   # ðŸ‘ˆ disable multi-scale, fairness across models
    stop_epoch: 25        # ðŸ‘ˆ match with policy above

  shuffle: True
  total_batch_size: 16   # ðŸ‘ˆ safe universal batch size (fits all models on 4090)
  num_workers: 8         # ðŸ‘ˆ enough parallelism, stable on your CPU

val_dataloader:
  dataset:
    transforms:
      ops:
        - {type: Resize, size: [640, 640]}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
  shuffle: False
  total_batch_size: 64   # ðŸ‘ˆ inference is lighter, keep 64
  num_workers: 8